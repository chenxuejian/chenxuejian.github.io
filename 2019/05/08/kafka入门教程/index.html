<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>kafka入门教程 | Adolf</title><meta name="keywords" content="linux,kafka"><meta name="author" content="Adolf"><meta name="copyright" content="Adolf"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="1、认识kafka1.1 kafka简介Kafka 是一个分布式流媒体平台 kafka官网：http:&#x2F;&#x2F;kafka.apache.org&#x2F; （1）流媒体平台有三个关键功能：  发布和订阅记录流，类似于消息队列或企业消息传递系统。 以容错的持久方式存储记录流。 记录发生时处理流。  （2）Kafka通常用于两大类应用：  构建可在系统或应用程序之间可靠获取数据的实时流数据管道 构建转换或响应数据流">
<meta property="og:type" content="article">
<meta property="og:title" content="kafka入门教程">
<meta property="og:url" content="http://example.com/2019/05/08/kafka%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/index.html">
<meta property="og:site_name" content="Adolf">
<meta property="og:description" content="1、认识kafka1.1 kafka简介Kafka 是一个分布式流媒体平台 kafka官网：http:&#x2F;&#x2F;kafka.apache.org&#x2F; （1）流媒体平台有三个关键功能：  发布和订阅记录流，类似于消息队列或企业消息传递系统。 以容错的持久方式存储记录流。 记录发生时处理流。  （2）Kafka通常用于两大类应用：  构建可在系统或应用程序之间可靠获取数据的实时流数据管道 构建转换或响应数据流">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg">
<meta property="article:published_time" content="2019-05-07T23:44:31.000Z">
<meta property="article:modified_time" content="2021-01-27T02:25:26.049Z">
<meta property="article:author" content="Adolf">
<meta property="article:tag" content="linux">
<meta property="article:tag" content="kafka">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2019/05/08/kafka%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}

// https://stackoverflow.com/questions/16839698/jquery-getscript-alternative-in-native-javascript
const getScript = url => new Promise((resolve, reject) => {
  const script = document.createElement('script')
  script.src = url
  script.async = true
  script.onerror = reject
  script.onload = script.onreadystatechange = function() {
    const loadState = this.readyState
    if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
    script.onload = script.onreadystatechange = null
    resolve()
  }
  document.head.appendChild(script)
})</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-01-27 10:25:26'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="Adolf" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">61</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">62</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Adolf</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">kafka入门教程</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2019-05-07T23:44:31.000Z" title="Created 2019-05-08 07:44:31">2019-05-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2021-01-27T02:25:26.049Z" title="Updated 2021-01-27 10:25:26">2021-01-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Linux/">Linux</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="1、认识kafka"><a href="#1、认识kafka" class="headerlink" title="1、认识kafka"></a>1、认识kafka</h1><h2 id="1-1-kafka简介"><a href="#1-1-kafka简介" class="headerlink" title="1.1 kafka简介"></a>1.1 kafka简介</h2><p>Kafka 是一个分布式流媒体平台</p>
<p>kafka官网：<a target="_blank" rel="noopener" href="http://kafka.apache.org/">http://kafka.apache.org/</a></p>
<p>（1）流媒体平台有三个关键功能：</p>
<ul>
<li>发布和订阅记录流，类似于消息队列或企业消息传递系统。</li>
<li>以容错的持久方式存储记录流。</li>
<li>记录发生时处理流。</li>
</ul>
<p>（2）Kafka通常用于两大类应用：</p>
<ul>
<li>构建可在系统或应用程序之间可靠获取数据的实时流数据管道</li>
<li>构建转换或响应数据流的实时流应用程序</li>
</ul>
<p>要了解Kafka如何做这些事情，让我们深入探讨Kafka的能力。</p>
<p>（3）首先是几个概念：</p>
<ul>
<li>Kafka作为一个集群运行在一个或多个可跨多个数据中心的服务器上。</li>
<li>Kafka集群以称为 topics主题 的类别存储记录流。</li>
<li>每条记录都包含一个键，一个值和一个时间戳。</li>
</ul>
<p>（4）Kafka有四个核心API：</p>
<ul>
<li>Producer API（生产者API）允许应用程序发布记录流至一个或多个kafka的topics（主题）。</li>
<li>Consumer API（消费者API）允许应用程序订阅一个或多个topics（主题），并处理所产生的对他们记录的数据流。</li>
<li>Streams API（流API）允许应用程序充当流处理器，从一个或多个topics（主题）消耗的输入流，并产生一个输出流至一个或多个输出的topics（主题），有效地变换所述输入流，以输出流。</li>
<li>Connector API（连接器API）允许构建和运行kafka topics（主题）连接到现有的应用程序或数据系统中重用生产者或消费者。例如，关系数据库的连接器可能捕获对表的每个更改。</li>
</ul>
<p><img src="/2019/05/08/kafka%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/kafka-01.png" alt="kafka-01"></p>
<p>　 在Kafka中，客户端和服务器之间的通信是通过简单，高性能，语言无关的TCP协议完成的。此协议已版本化并保持与旧版本的向后兼容性。Kafka提供Java客户端，但客户端有多种语言版本。</p>
<h2 id="1-2-Topics主题-和-partitions分区"><a href="#1-2-Topics主题-和-partitions分区" class="headerlink" title="1.2 Topics主题 和 partitions分区"></a>1.2 Topics主题 和 partitions分区</h2><p>我们首先深入了解 Kafka 为记录流提供的核心抽象 - 主题topics</p>
<p>　　一个Topic可以认为是一类消息，每个topic将被分成多个partition(区),每个partition在存储层面是append log文件</p>
<p>　　主题是发布记录的类别或订阅源名称。Kafka的主题总是多用户; 也就是说，一个主题可以有零个，一个或多个消费者订阅写入它的数据。</p>
<p>　　对于每个主题，Kafka群集都维护一个如下所示的分区日志：</p>
<p><img src="/2019/05/08/kafka%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/kafka-02.png" alt="kafka-02"></p>
<p>　　每个分区都是一个有序的，不可变的记录序列，不断附加到结构化的提交日志中。分区中的记录每个都分配了一个称为偏移的顺序ID号，它唯一地标识分区中的每个记录。</p>
<p>　　Kafka集群持久保存所有已发布的记录 - 无论是否已使用 - 使用可配置的保留期。例如，如果保留策略设置为两天，则在发布记录后的两天内，它可供使用，之后将被丢弃以释放空间。Kafka的性能在数据大小方面实际上是恒定的，因此长时间存储数据不是问题。</p>
<p><img src="/2019/05/08/kafka%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/kafka-03.png" alt="kafka-03"></p>
<p>　　实际上，基于每个消费者保留的唯一元数据是该消费者在日志中的偏移或位置。这种偏移由消费者控制：通常消费者在读取记录时会线性地提高其偏移量，但事实上，由于该位置由消费者控制，因此它可以按照自己喜欢的任何顺序消费记录。例如，消费者可以重置为较旧的偏移量来重新处理过去的数据，或者跳到最近的记录并从“现在”开始消费。</p>
<p>　　这些功能组合意味着Kafka 消费者consumers 非常cheap - 他们可以来来往往对集群或其他消费者没有太大影响。例如，您可以使用我们的命令行工具“tail”任何主题的内容，而无需更改任何现有使用者所消耗的内容。</p>
<p>　　日志中的分区有多种用途。首先，它们允许日志扩展到超出适合单个服务器的大小。每个单独的分区必须适合托管它的服务器，但主题可能有许多分区，因此它可以处理任意数量的数据。其次，它们充当了并行性的单位 - 更多的是它。</p>
<h2 id="1-3-Distribution分配"><a href="#1-3-Distribution分配" class="headerlink" title="1.3 Distribution分配"></a>1.3 Distribution分配</h2><p>　　一个Topic的多个partitions,被分布在kafka集群中的多个server上;每个server(kafka实例)负责partitions中消息的读写操作;此外kafka还可以配置partitions需要备份的个数(replicas),每个partition将会被备份到多台机器上,以提高可用性.</p>
<p>　　基于replicated方案,那么就意味着需要对多个备份进行调度;每个partition都有一个server为”leader”;leader负责所有的读写操作,如果leader失效,那么将会有其他follower来接管(成为新的leader);follower只是单调的和leader跟进,同步消息即可..由此可见作为leader的server承载了全部的请求压力,因此从集群的整体考虑,有多少个partitions就意味着有多少个”leader”,kafka会将”leader”均衡的分散在每个实例上,来确保整体的性能稳定。</p>
<h2 id="1-4-Producers生产者-和-Consumers消费者"><a href="#1-4-Producers生产者-和-Consumers消费者" class="headerlink" title="1.4 Producers生产者 和 Consumers消费者"></a>1.4 Producers生产者 和 Consumers消费者</h2><h3 id="1-4-1-Producers生产者"><a href="#1-4-1-Producers生产者" class="headerlink" title="1.4.1 Producers生产者"></a>1.4.1 Producers生产者</h3><p>　　Producers 将数据发布到指定的topics 主题。同时Producer 也能决定将此消息归属于哪个partition;比如基于”round-robin”方式或者通过其他的一些算法等。</p>
<h3 id="1-4-2-Consumers"><a href="#1-4-2-Consumers" class="headerlink" title="1.4.2 Consumers"></a>1.4.2 Consumers</h3><ul>
<li>本质上kafka只支持Topic.每个consumer属于一个consumer group;反过来说,每个group中可以有多个 consumer.发送到Topic的消息,只会被订阅此Topic的每个group中的一个consumer消费。</li>
<li>如果所有使用者实例具有相同的使用者组，则记录将有效地在使用者实例上进行负载平衡。</li>
<li>如果所有消费者实例具有不同的消费者组，则每个记录将广播到所有消费者进程。</li>
</ul>
<p><img src="/2019/05/08/kafka%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/kafka-04.png" alt="kafka-04"></p>
<p>　　分析：两个服务器Kafka群集，托管四个分区（P0-P3），包含两个使用者组。消费者组A有两个消费者实例，B组有四个消费者实例。</p>
<p>　　在Kafka中实现消费consumption 的方式是通过在消费者实例上划分日志中的分区，以便每个实例在任何时间点都是分配的“公平份额”的独占消费者。维护组中成员资格的过程由Kafka协议动态处理。如果新实例加入该组，他们将从该组的其他成员接管一些分区; 如果实例死亡，其分区将分发给其余实例。</p>
<p>　　Kafka仅提供分区内记录的总订单，而不是主题中不同分区之间的记录。对于大多数应用程序而言，按分区排序与按键分区数据的能力相结合就足够了。但是，如果您需要对记录进行总订单，则可以使用仅包含一个分区的主题来实现，但这将意味着每个使用者组只有一个使用者进程。</p>
<h2 id="1-5-Consumers-kafka确保"><a href="#1-5-Consumers-kafka确保" class="headerlink" title="1.5 Consumers kafka确保"></a>1.5 Consumers kafka确保</h2><ul>
<li>发送到partitions中的消息将会按照它接收的顺序追加到日志中。也就是说，如果记录M1由与记录M2相同的生成者发送，并且首先发送M1，则M1将具有比M2更低的偏移并且在日志中更早出现。</li>
<li>消费者实例按照它们存储在日志中的顺序查看记录。对于消费者而言,它们消费消息的顺序和日志中消息顺序一致。</li>
<li>如果Topic的”replicationfactor”为N,那么允许N-1个kafka实例失效，我们将容忍最多N-1个服务器故障，而不会丢失任何提交到日志的记录。</li>
</ul>
<h2 id="1-6-kafka作为消息系统"><a href="#1-6-kafka作为消息系统" class="headerlink" title="1.6 kafka作为消息系统"></a>1.6 kafka作为消息系统</h2><p>Kafka的流概念与传统的企业邮件系统相比如何？</p>
<p>（1）传统消息系统</p>
<p>　　消息传统上有两种模型：queuing排队 and publish-subscribe发布 - 订阅。在队列中，消费者池可以从服务器读取并且每个记录转到其中一个; 在发布 - 订阅中，记录被广播给所有消费者。这两种模型中的每一种都有优点和缺点。排队的优势在于它允许您在多个消费者实例上划分数据处理，从而可以扩展您的处理。不幸的是，一旦一个进程读取它已经消失的数据，队列就不是​​多用户。发布 - 订阅允许您将数据广播到多个进程，但由于每条消息都发送给每个订阅者，因此无法进行扩展处理。</p>
<p>卡夫卡的消费者群体概念概括了这两个概念。与队列一样，使用者组允许您将处理划分为一组进程（使用者组的成员）。与发布 - 订阅一样，Kafka允许您向多个消费者组广播消息。</p>
<p>（2）kafka 的优势</p>
<p>　　Kafka模型的优势在于每个主题都具有这些属性 - 它可以扩展处理并且也是多用户 - 不需要选择其中一个。</p>
<p>　　与传统的消息系统相比，Kafka具有更强的订购保证。</p>
<p>　　传统队列在服务器上按顺序保留记录，如果多个消费者从队列中消耗，则服务器按照存储顺序分发记录。但是，虽然服务器按顺序分发记录，但是记录是异步传递给消费者的，因此它们可能会在不同的消费者处出现故障。这实际上意味着在存在并行消耗的情况下丢失记录的顺序。消息传递系统通常通过具有“独占消费者”概念来解决这个问题，该概念只允许一个进程从队列中消耗，但当然这意味着处理中没有并行性。</p>
<p>　　kafka做得更好。通过在主题中具有并行性概念 - 分区 - ，Kafka能够在消费者流程池中提供订购保证和负载平衡。这是通过将主题中的分区分配给使用者组中的使用者来实现的，以便每个分区仅由该组中的一个使用者使用。通过这样做，我们确保使用者是该分区的唯一读者并按顺序使用数据。由于有许多分区，这仍然可以平衡许多消费者实例的负载。但请注意，消费者组中的消费者实例不能超过分区。</p>
<h2 id="1-7-kafka作为存储系统"><a href="#1-7-kafka作为存储系统" class="headerlink" title="1.7 kafka作为存储系统"></a>1.7 kafka作为存储系统</h2><ul>
<li>任何允许发布与消费消息分离的消息的消息队列实际上充当了正在进行的消息的存储系统。Kafka的不同之处在于它是一个非常好的存储系统。</li>
<li>写入Kafka的数据将写入磁盘并进行复制以实现容错。Kafka允许生产者等待确认，以便在完全复制之前写入不被认为是完整的，并且即使写入的服务器失败也保证写入仍然存在。</li>
<li>磁盘结构Kafka很好地使用了规模 - 无论服务器上有50 KB还是50 TB的持久数据，Kafka都会执行相同的操作。</li>
<li>由于认真对待存储并允许客户端控制其读取位置，您可以将Kafka视为一种专用于高性能，低延迟提交日志存储，复制和传播的专用分布式文件系统。</li>
<li>有关Kafka的提交日志存储和复制设计的详细信息，请阅读此页面。</li>
</ul>
<h2 id="1-8-kafka用于流处理"><a href="#1-8-kafka用于流处理" class="headerlink" title="1.8 kafka用于流处理"></a>1.8 kafka用于流处理</h2><ul>
<li>仅仅读取，写入和存储数据流是不够的，目的是实现流的实时处理。</li>
<li>在Kafka中，流处理器是指从输入主题获取连续数据流，对此输入执行某些处理以及生成连续数据流以输出主题的任何内容。</li>
<li>例如，零售应用程序可能会接收销售和发货的输入流，并输出重新排序流和根据此数据计算的价格调整。</li>
<li>可以使用生产者和消费者API直接进行简单处理。但是，对于更复杂的转换，Kafka提供了完全集成的Streams API。这允许构建执行非平凡处理的应用程序，这些应用程序可以计算流的聚合或将流连接在一起。</li>
<li>此工具有助于解决此类应用程序面临的难题：处理无序数据，在代码更改时重新处理输入，执行有状态计算等。</li>
<li>流API构建在Kafka提供的核心原语上：它使用生产者和消费者API进行输入，使用Kafka进行有状态存储，并在流处理器实例之间使用相同的组机制来实现容错。</li>
</ul>
<h1 id="2、kafka使用场景"><a href="#2、kafka使用场景" class="headerlink" title="2、kafka使用场景"></a>2、kafka使用场景</h1><h2 id="2-1-消息Messaging"><a href="#2-1-消息Messaging" class="headerlink" title="2.1 消息Messaging"></a>2.1 消息Messaging</h2><p>　　Kafka可以替代更传统的消息代理。消息代理的使用有多种原因（将处理与数据生成器分离，缓冲未处理的消息等）。与大多数消息传递系统相比，Kafka具有更好的吞吐量，内置分区，复制和容错功能，这使其成为大规模消息处理应用程序的理想解决方案。</p>
<p>　　根据经验，消息传递的使用通常相对较低，但可能需要较低的端到端延迟，并且通常取决于Kafka提供的强大的耐用性保证。</p>
<p>　　在这个领域，Kafka可与传统的消息传递系统（如ActiveMQ或 RabbitMQ）相媲美。</p>
<h2 id="2-2-网站活动跟踪"><a href="#2-2-网站活动跟踪" class="headerlink" title="2.2 网站活动跟踪"></a>2.2 网站活动跟踪</h2><p>　　Kafka的原始用例是能够将用户活动跟踪管道重建为一组实时发布 - 订阅源。这意味着站点活动（页面查看，搜索或用户可能采取的其他操作）将发布到中心主题，每个活动类型包含一个主题。这些源可用于订购一系列用例，包括实时处理，实时监控以及加载到Hadoop或离线数据仓库系统以进行脱机处理和报告。</p>
<p>　　活动跟踪通常非常高，因为为每个用户页面视图生成了许多活动消息。</p>
<h2 id="2-3-度量Metrics"><a href="#2-3-度量Metrics" class="headerlink" title="2.3 度量Metrics"></a>2.3 度量Metrics</h2><p>　　Kafka通常用于运营监控数据。这涉及从分布式应用程序聚合统计信息以生成操作数据的集中式提要。</p>
<h2 id="2-4-日志聚合"><a href="#2-4-日志聚合" class="headerlink" title="2.4 日志聚合"></a>2.4 日志聚合</h2><p>　　许多人使用Kafka作为日志聚合解决方案的替代品。日志聚合通常从服务器收集物理日志文件，并将它们放在中央位置（可能是文件服务器或HDFS）进行处理。Kafka抽象出文件的细节，并将日志或事件数据作为消息流更清晰地抽象出来。这允许更低延迟的处理并更容易支持多个数据源和分布式数据消耗。与Scribe或Flume等以日志为中心的系统相比，Kafka提供了同样出色的性能，由于复制而具有更强的耐用性保证，以及更低的端到端延迟。</p>
<h2 id="2-5-流处理"><a href="#2-5-流处理" class="headerlink" title="2.5 流处理"></a>2.5 流处理</h2><p>　　许多Kafka用户在处理由多个阶段组成的管道时处理数据，其中原始输入数据从Kafka主题中消费，然后聚合，丰富或以其他方式转换为新主题以供进一步消费或后续处理。</p>
<p>　　例如，用于推荐新闻文章的处理管道可以从RSS订阅源抓取文章内容并将其发布到“文章”主题; 进一步处理可能会对此内容进行规范化或重复数据删除，并将已清理的文章内容发布到新主题; 最终处理阶段可能会尝试向用户推荐此内容。此类处理管道基于各个主题创建实时数据流的图形。从0.10.0.0开始，这是一个轻量级但功能强大的流处理库，名为Kafka Streams 在Apache Kafka中可用于执行如上所述的此类数据处理。除了Kafka Streams之外，其他开源流处理工具包括Apache Storm和 Apache Samza。</p>
<h2 id="2-6-Event-Sourcing"><a href="#2-6-Event-Sourcing" class="headerlink" title="2.6 Event Sourcing"></a>2.6 Event Sourcing</h2><p>　　Event Sourcing是一种应用程序设计风格，其中状态更改记录为按时间排序的记录序列。Kafka对非常大的存储日志数据的支持使其成为以这种风格构建的应用程序的出色后端。</p>
<h2 id="2-7-提交日志"><a href="#2-7-提交日志" class="headerlink" title="2.7 提交日志"></a>2.7 提交日志</h2><p>　　Kafka可以作为分布式系统的一种外部提交日志。该日志有助于在节点之间复制数据，并充当故障节点恢复其数据的重新同步机制。Kafka中的日志压缩功能有助于支持此用法。在这种用法中，Kafka类似于Apache BookKeeper项目。</p>
<h1 id="3、kafka安装"><a href="#3、kafka安装" class="headerlink" title="3、kafka安装"></a>3、kafka安装</h1><h2 id="3-1-下载安装"><a href="#3-1-下载安装" class="headerlink" title="3.1 下载安装"></a>3.1 下载安装</h2><p>到官网 <a target="_blank" rel="noopener" href="http://kafka.apache.org/downloads.html">http://kafka.apache.org/downloads.html</a> 下载想要的版本；</p>
<p>我这里下载的最新稳定版2.1.0</p>
<p>注：由于Kafka控制台脚本对于基于Unix和Windows的平台是不同的，因此在Windows平台上使用bin\windows\ 而不是bin/ 将脚本扩展名更改为.bat。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@along ~]# wget http:&#x2F;&#x2F;mirrors.shu.edu.cn&#x2F;apache&#x2F;kafka&#x2F;2.1.0&#x2F;kafka_2.11-2.1.0.tgz</span><br><span class="line">[root@along ~]# tar -C &#x2F;data&#x2F; -xvf kafka_2.11-2.1.0.tgz</span><br><span class="line">[root@along ~]# cd &#x2F;data&#x2F;kafka_2.11-2.1.0&#x2F;　</span><br></pre></td></tr></table></figure>
<h2 id="3-2-配置启动zookeeper"><a href="#3-2-配置启动zookeeper" class="headerlink" title="3.2 配置启动zookeeper"></a>3.2 配置启动zookeeper</h2><p>　　kafka正常运行，必须配置zookeeper，否则无论是kafka集群还是客户端的生存者和消费者都无法正常的工作的；所以需要配置启动zookeeper服务。</p>
<p>（1）zookeeper需要java环境</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@along ~]# yum -y install java-1.8.0</span><br></pre></td></tr></table></figure>
<p>（2）这里kafka下载包已经包括zookeeper服务，所以只需修改配置文件，启动即可。</p>
<p>如果需要下载指定zookeeper版本；可以单独去zookeeper官网<a target="_blank" rel="noopener" href="http://mirrors.shu.edu.cn/apache/zookeeper/%E4%B8%8B%E8%BD%BD%E6%8C%87%E5%AE%9A%E7%89%88%E6%9C%AC%E3%80%82">http://mirrors.shu.edu.cn/apache/zookeeper/下载指定版本。</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@along ~]# cd &#x2F;data&#x2F;kafka_2.11-2.1.0&#x2F;</span><br><span class="line">[root@along kafka_2.11-2.1.0]# grep &quot;^[^#]&quot; config&#x2F;zookeeper.properties</span><br><span class="line">dataDir&#x3D;&#x2F;tmp&#x2F;zookeeper   #数据存储目录</span><br><span class="line">clientPort&#x3D;2181   #zookeeper端口</span><br><span class="line">maxClientCnxns&#x3D;0</span><br></pre></td></tr></table></figure>
<p>注：可自行添加修改zookeeper配置</p>
<h2 id="3-3-配置kafka"><a href="#3-3-配置kafka" class="headerlink" title="3.3 配置kafka"></a>3.3 配置kafka</h2><p>（1）修改配置文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@along kafka_2.11-2.1.0]# grep &quot;^[^#]&quot; config&#x2F;server.properties</span><br><span class="line">broker.id&#x3D;0</span><br><span class="line">listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;localhost:9092</span><br><span class="line">num.network.threads&#x3D;3</span><br><span class="line">num.io.threads&#x3D;8</span><br><span class="line">socket.send.buffer.bytes&#x3D;102400</span><br><span class="line">socket.receive.buffer.bytes&#x3D;102400</span><br><span class="line">socket.request.max.bytes&#x3D;104857600</span><br><span class="line">log.dirs&#x3D;&#x2F;tmp&#x2F;kafka-logs</span><br><span class="line">num.partitions&#x3D;1</span><br><span class="line">num.recovery.threads.per.data.dir&#x3D;1</span><br><span class="line">offsets.topic.replication.factor&#x3D;1</span><br><span class="line">transaction.state.log.replication.factor&#x3D;1</span><br><span class="line">transaction.state.log.min.isr&#x3D;1</span><br><span class="line">log.retention.hours&#x3D;168</span><br><span class="line">log.segment.bytes&#x3D;1073741824</span><br><span class="line">log.retention.check.interval.ms&#x3D;300000</span><br><span class="line">zookeeper.connect&#x3D;localhost:2181</span><br><span class="line">zookeeper.connection.timeout.ms&#x3D;6000</span><br><span class="line">group.initial.rebalance.delay.ms&#x3D;0</span><br></pre></td></tr></table></figure>
<p>注：可根据自己需求修改配置文件</p>
<ul>
<li>broker.id：唯一标识ID</li>
<li>listeners=PLAINTEXT://localhost:9092：kafka服务监听地址和端口</li>
<li>log.dirs：日志存储目录</li>
<li>zookeeper.connect：指定zookeeper服务</li>
</ul>
<p>（2）配置环境变量</p>
<pre><code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">    [root@along ~]# vim &#x2F;etc&#x2F;profile.d&#x2F;kafka.sh</span><br><span class="line">    export KAFKA_HOME&#x3D;&quot;&#x2F;data&#x2F;kafka_2.11-2.1.0&quot;</span><br><span class="line">    export PATH&#x3D;&quot;$&#123;KAFKA_HOME&#125;&#x2F;bin:$PATH&quot;</span><br><span class="line">    [root@along ~]# source &#x2F;etc&#x2F;profile.d&#x2F;kafka.sh</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">（3）配置服务启动脚本</span><br><span class="line"></span><br></pre></td></tr></table></figure>
[root@along ~]# vim /etc/init.d/kafka
#!/bin/sh
#
# chkconfig: 345 99 01
# description: Kafka
#
# File : Kafka
#
# Description: Starts and stops the Kafka server
#

source /etc/rc.d/init.d/functions

KAFKA_HOME=/data/kafka_2.11-2.1.0
KAFKA_USER=root
export LOG_DIR=/tmp/kafka-logs

[ -e /etc/sysconfig/kafka ] &amp;&amp; . /etc/sysconfig/kafka

# See how we were called.
case &quot;$1&quot; in

start)
    echo -n &quot;Starting Kafka:&quot;
    /sbin/runuser -s /bin/sh $KAFKA_USER -c &quot;nohup $KAFKA_HOME/bin/kafka-server-start.sh $KAFKA_HOME/config/server.properties &gt; $LOG_DIR/server.out 2&gt; $LOG_DIR/server.err &amp;&quot;
    echo &quot; done.&quot;
    exit 0
    ;;

stop)
    echo -n &quot;Stopping Kafka: &quot;
    /sbin/runuser -s /bin/sh $KAFKA_USER  -c &quot;ps -ef | grep kafka.Kafka | grep -v grep | awk &#39;&#123;print \$2&#125;&#39; | xargs kill \-9&quot;
    echo &quot; done.&quot;
    exit 0
    ;;
hardstop)
    echo -n &quot;Stopping (hard) Kafka: &quot;
    /sbin/runuser -s /bin/sh $KAFKA_USER  -c &quot;ps -ef | grep kafka.Kafka | grep -v grep | awk &#39;&#123;print \$2&#125;&#39; | xargs kill -9&quot;
    echo &quot; done.&quot;
    exit 0
    ;;

status)
    c_pid=`ps -ef | grep kafka.Kafka | grep -v grep | awk &#39;&#123;print $2&#125;&#39;`
    if [ &quot;$c_pid&quot; = &quot;&quot; ] ; then
    echo &quot;Stopped&quot;
    exit 3
    else
    echo &quot;Running $c_pid&quot;
    exit 0
    fi
    ;;

restart)
    stop
    start
    ;;

*)
    echo &quot;Usage: kafka &#123;start|stop|hardstop|status|restart&#125;&quot;
    exit 1
    ;;

esac
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 3.4 启动kafka服务</span><br><span class="line">（1）后台启动zookeeper服务</span><br><span class="line"></span><br></pre></td></tr></table></figure></code></pre>
<p>[root@along ~]# nohup zookeeper-server-start.sh /data/kafka_2.11-2.1.0/config/zookeeper.properties &amp;<br> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">（2）启动kafka服务</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>[root@along ~]# service kafka start<br>Starting kafka (via systemctl):                            [  OK  ]<br>[root@along ~]# service kafka status<br>Running 86018<br>[root@along ~]# ss -nutl<br>Netid State      Recv-Q Send-Q     Local Address:Port                    Peer Address:Port<br>tcp   LISTEN     0      50                    :::9092                              :::*<br>tcp   LISTEN     0      50                    :::2181                              :::*
　　</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 4、kafka使用简单入门</span><br><span class="line">## 4.1 创建主题topics</span><br><span class="line">创建一个名为“along”的主题，它只包含一个分区，只有一个副本：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>[root@along ~]# kafka-topics.sh –create –zookeeper localhost:2181 –replication-factor 1 –partitions 1 –topic along<br>Created topic “along”.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">如果我们运行list topic命令，我们现在可以看到该主题：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>[root@along ~]# kafka-topics.sh –list –zookeeper localhost:2181<br>along</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 4.2 发送一些消息</span><br><span class="line">Kafka附带一个命令行客户端，它将从文件或标准输入中获取输入，并将其作为消息发送到Kafka集群。默认情况下，每行将作为单独的消息发送。</span><br><span class="line"></span><br><span class="line">运行生产者，然后在控制台中键入一些消息以发送到服务器。</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>[root@along ~]# kafka-console-producer.sh –broker-list localhost:9092 –topic along</p>
<blockquote>
<p>This is a message<br>This is another message</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 4.3 启动消费者</span><br><span class="line">Kafka还有一个命令行使用者，它会将消息转储到标准输出。</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>[root@along ~]# kafka-console-consumer.sh –bootstrap-server localhost:9092 –topic along –from-beginning<br>This is a message<br>This is another message</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">所有命令行工具都有其他选项; 运行不带参数的命令将显示更详细地记录它们的使用信息。</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"># 5、设置多代理kafka群集</span><br><span class="line">　　到目前为止，我们一直在与一个broker运行，但这并不好玩。对于Kafka，单个代理只是一个大小为1的集群，因此除了启动一些代理实例之外没有太多变化。但是为了感受它，让我们将我们的集群扩展到三个节点（仍然在我们的本地机器上）。</span><br><span class="line"></span><br><span class="line">## 5.1 准备配置文件</span><br></pre></td></tr></table></figure>
<p>[root@along kafka_2.11-2.1.0]# cd /data/kafka_2.11-2.1.0/<br>[root@along kafka_2.11-2.1.0]# cp config/server.properties config/server-1.properties<br>[root@along kafka_2.11-2.1.0]# cp config/server.properties config/server-2.properties<br>[root@along kafka_2.11-2.1.0]# vim config/server-1.properties<br>    broker.id=1<br>    listeners=PLAINTEXT://:9093<br>    log.dirs=/tmp/kafka-logs-1<br>[root@along kafka_2.11-2.1.0]# vim config/server-2.properties<br>    broker.id=2<br>    listeners=PLAINTEXT://:9094<br>    log.dirs=/tmp/kafka-logs-2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">注：该broker.id 属性是群集中每个节点的唯一且永久的名称。我们必须覆盖端口和日志目录，因为我们在同一台机器上运行这些，并且我们希望让所有代理尝试在同一端口上注册或覆盖彼此的数据。</span><br><span class="line"></span><br><span class="line">## 5.2 开启集群另2个kafka服务</span><br></pre></td></tr></table></figure>
<p>[root@along ~]# nohup kafka-server-start.sh /data/kafka_2.11-2.1.0/config/server-1.properties &amp;<br>[root@along ~]# nohup kafka-server-start.sh /data/kafka_2.11-2.1.0/config/server-2.properties &amp;<br>[root@along ~]# ss -nutl<br>Netid State      Recv-Q Send-Q     Local Address:Port                    Peer Address:Port<br>tcp   LISTEN     0      50      ::ffff:127.0.0.1:9092                              :::*<br>tcp   LISTEN     0      50      ::ffff:127.0.0.1:9093                              :::*<br>tcp   LISTEN     0      50      ::ffff:127.0.0.1:9094                              </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">　　</span><br><span class="line">## 5.3 在集群中进行操作</span><br><span class="line">（1）现在创建一个复制因子为3的新主题my-replicated-topic</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>[root@along ~]# kafka-topics.sh –create –zookeeper localhost:2181 –replication-factor 3 –partitions 1 –topic my-replicated-topic<br>Created topic “my-replicated-topic”.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">（2）在一个集群中，运行“describe topics”命令查看哪个broker正在做什么</span><br></pre></td></tr></table></figure>
<p>[root@along ~]# kafka-topics.sh –describe –zookeeper localhost:2181 –topic my-replicated-topic<br>Topic:my-replicated-topic   PartitionCount:1    ReplicationFactor:3 Configs:<br>    Topic: my-replicated-topic  Partition: 0    Leader: 2   Replicas: 2,0,1 Isr: 2,0,1</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">注释：第一行给出了所有分区的摘要，每个附加行提供有关一个分区的信息。由于我们只有一个分区用于此主题，因此只有一行。</span><br><span class="line"></span><br><span class="line">- “leader”是负责给定分区的所有读取和写入的节点。每个节点将成为随机选择的分区部分的领导者。</span><br><span class="line">- “replicas”是复制此分区日志的节点列表，无论它们是否为领导者，或者即使它们当前处于活动状态。</span><br><span class="line">- “isr”是“同步”复制品的集合。这是副本列表的子集，该列表当前处于活跃状态并且已经被领导者捕获。</span><br><span class="line"></span><br><span class="line">请注意，Leader: 2，在我的示例中，节点2 是该主题的唯一分区的Leader。</span><br><span class="line"></span><br><span class="line">（3）可以在我们创建的原始主题上运行相同的命令，以查看它的位置</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>[root@along ~]# kafka-topics.sh –describe –zookeeper localhost:2181 –topic along<br>Topic:along PartitionCount:1    ReplicationFactor:1 Configs:<br>    Topic: along    Partition: 0    Leader: 0   Replicas: 0 Isr: 0</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">（4）向我们的新主题发布一些消息：</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>[root@along ~]# kafka-console-producer.sh –broker-list localhost:9092 –topic my-replicated-topic</p>
<blockquote>
<p>my test message 1<br>my test message 2<br>^C</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">（5）现在让我们使用这些消息：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>[root@along ~]# kafka-console-consumer.sh –bootstrap-server localhost:9092 –from-beginning –topic my-replicated-topic<br>my test message 1<br>my test message 2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 5.4 测试集群的容错性</span><br><span class="line">（1）现在让我们测试一下容错性。Broker 2 充当leader 所以让我们杀了它：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>[root@along ~]# ps aux | grep server-2.properties |awk ‘{print $2}’<br>106737<br>[root@along ~]# kill -9 106737<br>[root@along ~]# ss -nutl<br>tcp   LISTEN     0      50      ::ffff:127.0.0.1:9092                              :::*<br>tcp   LISTEN     0      50      ::ffff:127.0.0.1:9093                              :::*</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">（2）leader 已切换到其中一个从属节点，节点2不再位于同步副本集中：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>[root@along ~]# kafka-topics.sh –describe –zookeeper localhost:2181 –topic my-replicated-topic<br>Topic:my-replicated-topic   PartitionCount:1    ReplicationFactor:3 Configs:<br>    Topic: my-replicated-topic  Partition: 0    Leader: 0   Replicas: 2,0,1 Isr: 0,1</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">（3）即使最初接受写入的leader 已经失败，这些消息仍可供消费：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>[root@along ~]# kafka-console-consumer.sh –bootstrap-server localhost:9092 –from-beginning –topic my-replicated-topic<br>my test message 1<br>my test message 2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 6、使用Kafka Connect导入&#x2F;导出数据</span><br><span class="line">　　从控制台写入数据并将其写回控制台是一个方便的起点，但有时候可能希望使用其他来源的数据或将数据从Kafka导出到其他系统。对于许多系统，您可以使用Kafka Connect导入或导出数据，而不是编写自定义集成代码。</span><br><span class="line"></span><br><span class="line">　　Kafka Connect是Kafka附带的工具，用于向Kafka导入和导出数据。它是一个可扩展的工具，运行连接器，实现与外部系统交互的自定义​​逻辑。在本快速入门中，我们将了解如何使用简单的连接器运行Kafka Connect，这些连接器将数据从文件导入Kafka主题并将数据从Kafka主题导出到文件。</span><br><span class="line"></span><br><span class="line">（1）首先创建一些种子数据进行测试：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>[root@along ~]# echo -e “foo\nbar” &gt; test.txt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">或者在Windows上：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>echo foo&gt; test.txt<br>echo bar&gt;&gt; test.txt</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">（2）接下来，启动两个以独立模式运行的连接器，这意味着它们在单个本地专用进程中运行。提供三个配置文件作为参数。</span><br><span class="line"></span><br><span class="line">- 第一个始终是Kafka Connect流程的配置，包含常见配置，例如要连接的Kafka代理和数据的序列化格式。</span><br><span class="line">- 其余配置文件均指定要创建的连接器。这些文件包括唯一的连接器名称，要实例化的连接器类以及连接器所需的任何其他配置。</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>[root@along ~]# connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties<br>[2019-01-16 16:16:31,884] INFO Kafka Connect standalone worker initializing … (org.apache.kafka.connect.cli.ConnectStandalone:67)<br>[2019-01-16 16:16:31,903] INFO WorkerInfo values:<br>… …</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">　　注：Kafka附带的这些示例配置文件使用您之前启动的默认本地群集配置并创建两个连接器：第一个是源连接器，它从输入文件读取行并生成每个Kafka主题，第二个是宿连接器从Kafka主题读取消息并将每个消息生成为输出文件中的一行。</span><br><span class="line"></span><br><span class="line">（3）验证是否导入成功（另起终端）</span><br><span class="line"></span><br><span class="line">在启动过程中，您将看到许多日志消息，包括一些指示正在实例化连接器的日志消息。</span><br><span class="line"></span><br><span class="line">① 一旦Kafka Connect进程启动，源连接器应该开始从test.txt主题读取行并将其生成到主题connect-test，并且接收器连接器应该开始从主题读取消息connect-test 并将它们写入文件test.sink.txt。我们可以通过检查输出文件的内容来验证数据是否已通过整个管道传递：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>[root@along ~]# cat test.sink.txt<br>foo<br>bar</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">② 请注意，数据存储在Kafka主题中connect-test，因此我们还可以运行控制台使用者来查看主题中的数据（或使用自定义使用者代码来处理它）：</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>[root@along ~]# kafka-console-consumer.sh –bootstrap-server localhost:9092 –topic connect-test –from-beginning<br>{“schema”:{“type”:”string”,”optional”:false},”payload”:”foo”}<br>{“schema”:{“type”:”string”,”optional”:false},”payload”:”bar”}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">（4）继续追加数据，验证</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>[root@along ~]# echo Another line&gt;&gt; test.txt<br>[root@along ~]# cat test.sink.txt<br>foo<br>bar<br>Another line<br>[root@along ~]# kafka-console-consumer.sh –bootstrap-server localhost:9092 –topic connect-test –from-beginning<br>{“schema”:{“type”:”string”,”optional”:false},”payload”:”foo”}<br>{“schema”:{“type”:”string”,”optional”:false},”payload”:”bar”}<br>{“schema”:{“type”:”string”,”optional”:false},”payload”:”Another line”}</p>
<pre><code></code></pre>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Adolf</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/2019/05/08/kafka%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/">http://example.com/2019/05/08/kafka%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/linux/">linux</a><a class="post-meta__tags" href="/tags/kafka/">kafka</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2019/05/09/k8s%E9%83%A8%E7%BD%B2kong%E4%B9%8Byaml/"><img class="prev-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">K8s部署kong之yaml</div></div></a></div><div class="next-post pull-right"><a href="/2019/05/06/Kubernetes%E4%B9%8Bpod%E8%B0%83%E5%BA%A6/"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Kubernetes之pod调度</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2019/03/09/AWS常用cli命令/" title="AWS常用cli命令"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-03-09</div><div class="title">AWS常用cli命令</div></div></a></div><div><a href="/2019/02/24/Commonly used Git command list/" title="Commonly used Git command list"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-02-24</div><div class="title">Commonly used Git command list</div></div></a></div><div><a href="/2019/02/23/Create Lvm/" title="Create_lvm"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-02-23</div><div class="title">Create_lvm</div></div></a></div><div><a href="/2019/02/23/Delete private registry mirror/" title="Delete private registry mirror"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-02-23</div><div class="title">Delete private registry mirror</div></div></a></div><div><a href="/2019/02/25/DNS介绍/" title="DNS介绍"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-02-25</div><div class="title">DNS介绍</div></div></a></div><div><a href="/2019/02/26/Get the value of a variable error within the pod K8S/" title="K8S的pod内获取变量的值错误"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-02-26</div><div class="title">K8S的pod内获取变量的值错误</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Adolf</div><div class="author-info__description">曾国藩：一勤天下无难事</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">61</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">62</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1%E3%80%81%E8%AE%A4%E8%AF%86kafka"><span class="toc-number">1.</span> <span class="toc-text">1、认识kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-kafka%E7%AE%80%E4%BB%8B"><span class="toc-number">1.1.</span> <span class="toc-text">1.1 kafka简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-Topics%E4%B8%BB%E9%A2%98-%E5%92%8C-partitions%E5%88%86%E5%8C%BA"><span class="toc-number">1.2.</span> <span class="toc-text">1.2 Topics主题 和 partitions分区</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3-Distribution%E5%88%86%E9%85%8D"><span class="toc-number">1.3.</span> <span class="toc-text">1.3 Distribution分配</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-4-Producers%E7%94%9F%E4%BA%A7%E8%80%85-%E5%92%8C-Consumers%E6%B6%88%E8%B4%B9%E8%80%85"><span class="toc-number">1.4.</span> <span class="toc-text">1.4 Producers生产者 和 Consumers消费者</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-1-Producers%E7%94%9F%E4%BA%A7%E8%80%85"><span class="toc-number">1.4.1.</span> <span class="toc-text">1.4.1 Producers生产者</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-2-Consumers"><span class="toc-number">1.4.2.</span> <span class="toc-text">1.4.2 Consumers</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-5-Consumers-kafka%E7%A1%AE%E4%BF%9D"><span class="toc-number">1.5.</span> <span class="toc-text">1.5 Consumers kafka确保</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-6-kafka%E4%BD%9C%E4%B8%BA%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F"><span class="toc-number">1.6.</span> <span class="toc-text">1.6 kafka作为消息系统</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-7-kafka%E4%BD%9C%E4%B8%BA%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F"><span class="toc-number">1.7.</span> <span class="toc-text">1.7 kafka作为存储系统</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-8-kafka%E7%94%A8%E4%BA%8E%E6%B5%81%E5%A4%84%E7%90%86"><span class="toc-number">1.8.</span> <span class="toc-text">1.8 kafka用于流处理</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2%E3%80%81kafka%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">2.</span> <span class="toc-text">2、kafka使用场景</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-%E6%B6%88%E6%81%AFMessaging"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 消息Messaging</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-%E7%BD%91%E7%AB%99%E6%B4%BB%E5%8A%A8%E8%B7%9F%E8%B8%AA"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 网站活动跟踪</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-%E5%BA%A6%E9%87%8FMetrics"><span class="toc-number">2.3.</span> <span class="toc-text">2.3 度量Metrics</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4-%E6%97%A5%E5%BF%97%E8%81%9A%E5%90%88"><span class="toc-number">2.4.</span> <span class="toc-text">2.4 日志聚合</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-5-%E6%B5%81%E5%A4%84%E7%90%86"><span class="toc-number">2.5.</span> <span class="toc-text">2.5 流处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-6-Event-Sourcing"><span class="toc-number">2.6.</span> <span class="toc-text">2.6 Event Sourcing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-7-%E6%8F%90%E4%BA%A4%E6%97%A5%E5%BF%97"><span class="toc-number">2.7.</span> <span class="toc-text">2.7 提交日志</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3%E3%80%81kafka%E5%AE%89%E8%A3%85"><span class="toc-number">3.</span> <span class="toc-text">3、kafka安装</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 下载安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-%E9%85%8D%E7%BD%AE%E5%90%AF%E5%8A%A8zookeeper"><span class="toc-number">3.2.</span> <span class="toc-text">3.2 配置启动zookeeper</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3-%E9%85%8D%E7%BD%AEkafka"><span class="toc-number">3.3.</span> <span class="toc-text">3.3 配置kafka</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/01/28/%E5%A6%82%E4%BD%95%E6%9C%89%E6%95%88%E7%9A%84%E4%BF%AE%E6%94%B9Linux%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84hosts%E9%85%8D%E7%BD%AE/" title="如何有效的修改Linux云服务器的hosts配置"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="如何有效的修改Linux云服务器的hosts配置"/></a><div class="content"><a class="title" href="/2021/01/28/%E5%A6%82%E4%BD%95%E6%9C%89%E6%95%88%E7%9A%84%E4%BF%AE%E6%94%B9Linux%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84hosts%E9%85%8D%E7%BD%AE/" title="如何有效的修改Linux云服务器的hosts配置">如何有效的修改Linux云服务器的hosts配置</a><time datetime="2021-01-28T06:42:35.000Z" title="Created 2021-01-28 14:42:35">2021-01-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/01/26/hexo%E4%B8%AD%E5%9B%BE%E7%89%87%E6%97%A0%E6%B3%95%E5%8A%A0%E8%BD%BD/" title="hexo中图片无法加载"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="hexo中图片无法加载"/></a><div class="content"><a class="title" href="/2021/01/26/hexo%E4%B8%AD%E5%9B%BE%E7%89%87%E6%97%A0%E6%B3%95%E5%8A%A0%E8%BD%BD/" title="hexo中图片无法加载">hexo中图片无法加载</a><time datetime="2021-01-26T15:59:21.000Z" title="Created 2021-01-26 23:59:21">2021-01-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/01/25/hello-world/" title="Hello World"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hello World"/></a><div class="content"><a class="title" href="/2021/01/25/hello-world/" title="Hello World">Hello World</a><time datetime="2021-01-25T10:57:47.958Z" title="Created 2021-01-25 18:57:47">2021-01-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/04/22/SLUB:Unable%20to%20allocate%20memory/" title="SLUB:Unable to Allocate Memory"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SLUB:Unable to Allocate Memory"/></a><div class="content"><a class="title" href="/2020/04/22/SLUB:Unable%20to%20allocate%20memory/" title="SLUB:Unable to Allocate Memory">SLUB:Unable to Allocate Memory</a><time datetime="2020-04-22T05:40:38.000Z" title="Created 2020-04-22 13:40:38">2020-04-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/04/22/%E9%87%8D%E5%90%AF%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AF%BC%E8%87%B4docker%E4%B8%ADredis%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8%E7%9A%84%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/" title="重启服务器导致docker中redis无法启动的问题解决"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="重启服务器导致docker中redis无法启动的问题解决"/></a><div class="content"><a class="title" href="/2020/04/22/%E9%87%8D%E5%90%AF%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AF%BC%E8%87%B4docker%E4%B8%ADredis%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8%E7%9A%84%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/" title="重启服务器导致docker中redis无法启动的问题解决">重启服务器导致docker中redis无法启动的问题解决</a><time datetime="2020-04-21T23:11:33.000Z" title="Created 2020-04-22 07:11:33">2020-04-22</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Adolf</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></div></body></html>